{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import IPython.display as ipd\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "%load_ext Cython\n",
    "import sigkernel as ksig\n",
    "from utils.midi import *\n",
    "from utils.data import *\n",
    "from model.generators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_len = 5\n",
    "sample_len = 35\n",
    "seq_dim = 2\n",
    "scale = 1.\n",
    "stride = 40\n",
    "min_notes = sample_len #NOTE: length of tensor might be longer than min_notes due to rectilinear transformation\n",
    "min_gap = 0.\n",
    "max_pitch = 38\n",
    "pitch_offset = 47\n",
    "\n",
    "batch_size = 50\n",
    "rectilinear = True\n",
    "activation = 'GELU'\n",
    "hidden_size = 128\n",
    "n_layers = 1\n",
    "n_head = 4\n",
    "n_channels = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/dataframes/min_note_50_min_gap_0/dfs_note_dur_offset_47.pkl', 'rb') as f:\n",
    "    dfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NoteDurationDataset(dfs, sample_len=sample_len, scale=scale, stride=stride)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = LSTMusic(seq_dim, sample_len, max_pitch, hidden_size, n_layers, activation)\n",
    "generator = generator.cuda()\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_kernel = ksig.static.kernels.RationalQuadraticKernel(sigma=0.1)\n",
    "kernel = ksig.kernels.SignatureKernel(n_levels=5, order=5, normalization=0, static_kernel=static_kernel, device_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for epoch in range(30):\n",
    "    losses = []\n",
    "    for batch_num, X in enumerate(tqdm(dataloader)):\n",
    "        X = X.to(device)\n",
    "        sample = batch_rectilinear_transform(X[:, hist_len:, :])\n",
    "\n",
    "        output = generator(X[:, :hist_len, :])\n",
    "        output = batch_rectilinear_transform(output)\n",
    "\n",
    "        # compute loss\n",
    "        optimizer.zero_grad()\n",
    "        loss = ksig.tests.mmd_loss_no_compile(sample, output, kernel)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backpropagate and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # log epoch loss and plot generated samples\n",
    "    epoch_loss = np.average(losses) # average batch mmd for epoch\n",
    "    scheduler.step(epoch_loss)\n",
    "    print(f'Epoch {epoch}, loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataloader:\n",
    "    x = x.to(device)\n",
    "    output = generator(x[:, :hist_len, :])\n",
    "    output = torch.cat((x[:, :hist_len, :], output), dim=1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dfs = tensor_to_df(output, pitch_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dfs = tensor_to_df(x, pitch_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 1\n",
    "input_midi = df_to_midi(in_dfs[sample_idx])\n",
    "output_midi = df_to_midi(out_dfs[sample_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 22050\n",
    "audio_data = input_midi.synthesize(fs=Fs)\n",
    "ipd.Audio(audio_data, rate=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = output_midi.synthesize(fs=Fs)\n",
    "ipd.Audio(audio_data, rate=Fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
