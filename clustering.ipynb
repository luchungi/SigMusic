{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import IPython.display as ipd\n",
    "import iisignature as iisig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import cluster\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "%load_ext Cython\n",
    "import sigkernel as ksig\n",
    "from utils.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'single_key'\n",
    "sample_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/{key}/df_titles_30_min_notes_pitch_range_5_24.pkl', 'rb') as f:\n",
    "    df_titles = pickle.load(f)\n",
    "len(df_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to gap, duration, delta pitch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_dur_dpitch_dfs = gap_duration_deltapitch_transform([item[0] for item in df_titles])\n",
    "dataset = GapDurationDeltaPitchDataset(gap_dur_dpitch_dfs, sample_len=sample_len, stride=10000)\n",
    "len(dataset) == len(df_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to rectilinear path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(dataset)):\n",
    "    X.append(dataset[i])\n",
    "X = torch.stack(X)\n",
    "X = batch_rectilinear_with_gap_transform(X)\n",
    "Xs = X.numpy()\n",
    "Xs.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate signature and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = []\n",
    "for path in Xs:\n",
    "    signatures.append(iisig.sig(path, 5))\n",
    "signatures = np.array(signatures)\n",
    "signatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = cluster.KMeans(n_clusters=4).fit(signatures).labels_\n",
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Gram matrix of signature kernel with rational quadratic static kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_kernel = ksig.static.kernels.RationalQuadraticKernel(sigma=1.0)\n",
    "kernel = ksig.kernels.SignatureKernel(n_levels=5, order=1, normalization=0, static_kernel=static_kernel, device_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate gram matrix in batches\n",
    "# batch_size = 15\n",
    "# gram_matrix = torch.empty(len(X), len(X))\n",
    "# for i in range(int(len(X) / batch_size)+1):\n",
    "#     print((i+1)*batch_size)\n",
    "#     gram_matrix[i*batch_size:(i+1)*batch_size] = kernel(X[i*batch_size:(i+1)*batch_size].to('cuda'), X.to('cuda')).cpu()\n",
    "# torch.save(gram_matrix, f'./data/gram_matrices/gram_matrix_{sample_len}_min_notes_pitch_range_5_24.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_matrix = torch.load(f'./data/gram_matrices/gram_matrix_{sample_len}_min_notes_pitch_range_5_24.pt')\n",
    "gram_matrix = torch.tril(gram_matrix) + torch.tril(gram_matrix, diagonal=-1).T # make it symmetric as numerical errors make it not symmetric\n",
    "gram_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(torch.tril(gram_matrix, diagonal=-1), cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse gram matrix and cluster to eliminate outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test alignment of kernel matrix with list of dataframe indices\n",
    "start = 79\n",
    "print([item[1:] for item in df_titles[start:start+1]])\n",
    "sample_idx = 79\n",
    "midi_data = df_to_midi(batch_gap_duration_pitch_to_df(dataset[sample_idx].unsqueeze(0))[0])\n",
    "fs = 44100\n",
    "audio_data = midi_data.fluidsynth(fs=fs)\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates (x,y) of highest values in gram matrix\n",
    "n = 10\n",
    "max_coords_value = []\n",
    "temp_matrix = torch.tril(gram_matrix, diagonal=-1)\n",
    "for i in range(n):\n",
    "    c = torch.argmax(temp_matrix).item()\n",
    "    max_coords_value.append(((c//len(X), c%len(X)), torch.max(temp_matrix).item()))\n",
    "    temp_matrix[c//len(X), c%len(X)] = 0\n",
    "max_coords_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(n//5, 5, figsize=(20, 4*n//5))\n",
    "for i in range(len(max_coords_value)):\n",
    "    ax[i//5, i%5].plot(X[max_coords_value[i][0][0]].numpy()[:,0], X[max_coords_value[i][0][0]].numpy()[:,1])\n",
    "    ax[i//5, i%5].plot(X[max_coords_value[i][0][1]].numpy()[:,0], X[max_coords_value[i][0][1]].numpy()[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates (x,y) of lowest values in gram matrix\n",
    "n = 10\n",
    "min_coords_value = []\n",
    "temp_matrix = torch.tril(gram_matrix, diagonal=-1)\n",
    "for i in range(n):\n",
    "    c = torch.argmin(temp_matrix).item()\n",
    "    min_coords_value.append(((c//len(X), c%len(X)), torch.min(temp_matrix).item()))\n",
    "    temp_matrix[c//len(X), c%len(X)] = np.inf\n",
    "min_coords_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(n//5, 5, figsize=(20, 4*n//5))\n",
    "for i in range(len(min_coords_value)):\n",
    "    ax[i//5, i%5].plot(X[min_coords_value[i][0][0]].numpy()[:,0], X[min_coords_value[i][0][0]].numpy()[:,1])\n",
    "    ax[i//5, i%5].plot(X[min_coords_value[i][0][1]].numpy()[:,0], X[min_coords_value[i][0][1]].numpy()[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = min_coords_value[6][0][0]\n",
    "print(sample_idx)\n",
    "print(df_titles[sample_idx][1:])\n",
    "midi_data = df_to_midi(df_titles[sample_idx][0])\n",
    "fs = 44100\n",
    "audio_data = midi_data.fluidsynth(fs=fs)\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "labels = cluster.SpectralClustering(n_clusters=n_clusters, affinity='precomputed').fit(gram_matrix).labels_\n",
    "plt.hist(labels, bins=n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels) == len(df_titles))\n",
    "df_titles_labels = [(df_titles[i][0], df_titles[i][1], df_titles[i][2], df_titles[i][3], labels[i]) for i in range(len(df_titles))]\n",
    "with open(f'./data/dataframes/{key}/df_titles_cluster_30_min_notes_pitch_range_5_24.pkl', 'wb') as f:\n",
    "    pickle.dump(df_titles_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.unique(labels, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get args of label 4\n",
    "args = [i for i in range(len(labels)) if labels[i] == 5]\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_datas = []\n",
    "for arg in args:\n",
    "    print(df_titles[arg][1:])\n",
    "    midi_data = df_to_midi(df_titles[arg][0])\n",
    "    fs = 44100\n",
    "    audio_datas.append(midi_data.fluidsynth(fs=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio_datas[3], rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = [item for i, item in enumerate(df_titles) if i not in args]\n",
    "with open(f'./data/dataframes/single_key/df_titles_30_min_notes_pitch_range_5_24_spec_10_v1.pkl', 'wb') as f:\n",
    "    pickle.dump(df_titles, f)\n",
    "len(df_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort from largest to smallest then remove row and column in order\n",
    "print(gram_matrix.shape)\n",
    "for arg in np.sort(args)[::-1]:\n",
    "    gram_matrix = torch.cat((gram_matrix[:arg], gram_matrix[arg+1:]))\n",
    "    gram_matrix = torch.cat((gram_matrix[:,:arg], gram_matrix[:,arg+1:]), dim=1)\n",
    "print(gram_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affinity propagation clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = cluster.AffinityPropagation(affinity='precomputed').fit(gram_matrix).labels_\n",
    "counts = plt.hist(labels, bins=len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gram matrix to distance matrix using Cauchy-Schwarz\n",
    "# d_CS(x,y) = arccos k^2(x,y)/k(x,x)k(y,y).\n",
    "\n",
    "# dist_matrix = torch.tril(gram_matrix, diagonal=-1)\n",
    "# for i in range(len(X)):\n",
    "#     dist_matrix[i:,i] /= torch.sqrt(gram_matrix[i,i]) * torch.diag(gram_matrix).sqrt()[i:]\n",
    "# dist_matrix = torch.acos(dist_matrix)\n",
    "# dist_matrix = torch.tril(dist_matrix, diagonal=-1) + torch.tril(dist_matrix, diagonal=-1).T\n",
    "# dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gram matrix to distance matrix using |u-v|^2 = k(x,x) + k(y,y) - 2k(x,y)\n",
    "\n",
    "dist_matrix = -2*torch.tril(gram_matrix, diagonal=-1)\n",
    "for i in range(len(X)):\n",
    "    dist_matrix[i:,i] += gram_matrix[i,i] + torch.diag(gram_matrix)[i:]\n",
    "dist_matrix = torch.sqrt(dist_matrix)\n",
    "dist_matrix = torch.tril(dist_matrix, diagonal=-1) + torch.tril(dist_matrix, diagonal=-1).T\n",
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dist_matrix, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "labels = cluster.AgglomerativeClustering(n_clusters=n_clusters, metric='precomputed', linkage='average').fit(dist_matrix).labels_\n",
    "plt.hist(labels, bins=n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBScan clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.mean(dist_matrix[torch.tril(dist_matrix, diagonal=-1) > 0].numpy())\n",
    "labels = cluster.DBSCAN(eps=eps, metric='precomputed').fit(dist_matrix).labels_\n",
    "plt.hist(labels, bins=len(np.unique(labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
