{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'theorytab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'./data/{folder}/'\n",
    "songs = get_dfs_from_midi(path, min_notes=30, min_gap=0.)\n",
    "dfs = [item[0] for item in songs]\n",
    "len(dfs), len(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./data/dataframes/{folder}/all_songs.pkl', 'wb') as f:\n",
    "#     pickle.dump(songs, f)\n",
    "# with open(f'./data/dataframes/{folder}/all_songs.pkl', 'rb') as f:\n",
    "#     songs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = np.random.randint(len(dfs))\n",
    "print(f'Artist, title, segment of song: {songs[sample_idx][1:4]}')\n",
    "print(f'Key of song: {songs[sample_idx][4]}')\n",
    "print(f'Time signature: {songs[sample_idx][5]}')\n",
    "print(f'Beats in song: \\n {songs[sample_idx][6]}')\n",
    "midi_data = df_to_midi(songs[sample_idx][0])\n",
    "fs = 44100\n",
    "audio_data = midi_data.fluidsynth(fs=fs)\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_keys_per_song = [len(item[4]) for item in songs]\n",
    "plt.hist(n_keys_per_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of notes within Major scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_note = {0: 'C', 1: 'C#', 2: 'D', 3: 'D#', 4: 'E', 5: 'F', 6: 'F#', 7: 'G', 8: 'G#', 9: 'A', 10: 'A#', 11: 'B'}\n",
    "key_notes = []\n",
    "for i in range(12):\n",
    "    key_notes.append(get_notes_from_major_scale(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 5\n",
    "dfs_key = [item[0] for item in songs if item[4][0][0] == key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check percentage of notes in C major scale\n",
    "key_percentages = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 11: []}\n",
    "for df in dfs_key:\n",
    "    for i in range(len(key_notes)):\n",
    "        percentage = len([note for note in df['Pitch'].values if note in key_notes[i]]) / len(df['Pitch'].values)\n",
    "        key_percentages[i].append(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 3, figsize=(15, 5))\n",
    "print(f'Key: {key_to_note[key]}')\n",
    "for i in range(len(key_notes)):\n",
    "    print(f'Mean percentage of notes in key {key_to_note[i]}: {np.mean(key_percentages[i])}')\n",
    "    ax[i//3, i%3].hist(key_percentages[i], bins=100)\n",
    "    ax[i//3, i%3].set_title(f'{key_to_note[i]} major scale')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_signatures_per_song = [len(item[5]) for item in songs]\n",
    "plt.hist(n_signatures_per_song, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beats_per_bar = [item[5][0][0] for item in songs]\n",
    "plt.hist(beats_per_bar, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_value = [item[5][0][1] for item in songs]\n",
    "plt.hist(note_value, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all beats are multiples of the first beat\n",
    "beats = [item[6] for item in songs]\n",
    "beats = [item / item[1] for item in beats]\n",
    "beats = np.concatenate(beats)\n",
    "beats += 1\n",
    "beats = beats % beats == 0\n",
    "beats.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = 30\n",
    "min_unique_notes = 5\n",
    "songs = [item for item in songs if len(item[0]) > min_length]\n",
    "songs = [item for item in songs if item[0]['Pitch'].nunique() > min_unique_notes]\n",
    "lens = [len(item[0]) for item in songs]\n",
    "print('Number of songs:', len(songs))\n",
    "print('Max length:', max(lens))\n",
    "print('Min length:', min(lens))\n",
    "print('Mean length:', np.mean(lens))\n",
    "sorted_lens = sorted(lens)\n",
    "plt.bar(range(len(sorted_lens)), sorted_lens, width=1.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_idx = np.argpartition(lens, -4)[-4:]\n",
    "print(largest_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 8677\n",
    "print(songs[sample_idx][1:4])\n",
    "midi_data = df_to_midi(songs[sample_idx][0])\n",
    "fs = 44100\n",
    "audio_data = midi_data.fluidsynth(fs=fs)\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./data/dataframes/{key}/dfs.pkl', 'wb') as f:\n",
    "with open(f'./data/dataframes/single_key/songs_min_5_unique_notes.pkl', 'wb') as f:\n",
    "    pickle.dump(songs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/single_key/songs_min_5_unique_notes.pkl', 'rb') as f:\n",
    "    songs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration of melodies\n",
    "durations = []\n",
    "for item in songs:\n",
    "    durations.append(item[0]['End'].max())\n",
    "plt.hist(durations, bins=100);\n",
    "min(durations), max(durations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitch range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_note_df = pd.read_csv('./data/midi_to_notes.csv', index_col=0)\n",
    "# dfs = [add_octave_and_note(df, midi_note_df) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range([item[0] for item in songs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2 = trim_by_range(songs, min_range=5, max_range=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range([item[0] for item in songs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/single_key/songs_30_min_notes_pitch_range_5_24.pkl', 'wb') as f:\n",
    "    pickle.dump(songs2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in dfs2:\n",
    "#     center = (df['Pitch'].max() + df['Pitch'].min()) / 2\n",
    "#     if center < 45:\n",
    "#         display(df)\n",
    "#         temp_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 5))\n",
    "# plt.plot([0], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs3 = move_octaves(dfs2, min_pitch=48, max_pitch=100)\n",
    "# dfs3 = move_octaves(dfs3, min_pitch=48, max_pitch=80)\n",
    "dfs3 = move_octaves(dfs2, center_range=[60, 72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range(dfs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/{key}/songs_pitch_range_min_pitch_48_max_pitch_84.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octave translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 400\n",
    "dfs3[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 44100\n",
    "midi_data = df_to_midi(dfs[sample_idx])\n",
    "audio_data = midi_data.synthesize(fs=Fs)\n",
    "ipd.Audio(audio_data, rate=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_octave_down = dfs[sample_idx].copy()\n",
    "df_octave_down['Pitch'] = df_octave_down['Pitch'] - 12\n",
    "midi_data = df_to_midi(df_octave_down)\n",
    "audio_data = midi_data.synthesize(fs=Fs)\n",
    "ipd.Audio(audio_data, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure gap between start of next note and end of previous note\n",
    "neg_gaps = []\n",
    "pos_gaps = []\n",
    "for df in dfs:\n",
    "    gap = df['Start'].iloc[1:].values - df['End'].iloc[:-1].values\n",
    "    if gap.min() < 0:\n",
    "        neg_gaps.append(df)\n",
    "    if gap.max() > 0:\n",
    "        pos_gaps.append(df)\n",
    "print(len(neg_gaps), len(pos_gaps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration + Pitch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs4 = note_duration_transform(dfs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs5, max_pitch = pitch_translation(dfs4)\n",
    "max_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range(dfs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/{key}/dfs_note_dur_offset_{int(max_pitch)}.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/{key}/dfs_note_dur_offset_{int(max_pitch)}.pkl', 'rb') as f:\n",
    "    dfs5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NoteDurationDataset(dfs5, sample_len=20, scale=1., stride=10)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
