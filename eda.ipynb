{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = f'./data/single_key/{key}/'\n",
    "path = f'./data/single_key/'\n",
    "# path = './data/oldies/'\n",
    "df_titles = get_dfs_from_midi(path, min_notes=30, min_gap=0.)\n",
    "dfs = [item[0] for item in df_titles]\n",
    "len(dfs), len(df_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = np.random.randint(len(dfs))\n",
    "print(df_titles[sample_idx][1:])\n",
    "midi_data = df_to_midi(df_titles[sample_idx][0])\n",
    "fs = 44100\n",
    "audio_data = midi_data.fluidsynth(fs=fs)\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = 30\n",
    "min_unique_notes = 5\n",
    "df_titles = [item for item in df_titles if len(item[0]) > min_length]\n",
    "df_titles = [item for item in df_titles if item[0]['Pitch'].nunique() > min_unique_notes]\n",
    "lens = [len(item[0]) for item in df_titles]\n",
    "print('Number of songs:', len(df_titles))\n",
    "print('Max length:', max(lens))\n",
    "print('Min length:', min(lens))\n",
    "print('Mean length:', np.mean(lens))\n",
    "sorted_lens = sorted(lens)\n",
    "plt.bar(range(len(sorted_lens)), sorted_lens, width=1.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_idx = np.argpartition(lens, -4)[-4:]\n",
    "print(largest_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 6806\n",
    "print(df_titles[sample_idx][1:])\n",
    "midi_data = df_to_midi(df_titles[sample_idx][0])\n",
    "fs = 44100\n",
    "audio_data = midi_data.fluidsynth(fs=fs)\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./data/dataframes/{key}/dfs.pkl', 'wb') as f:\n",
    "with open(f'./data/dataframes/single_key/df_titles_min_5_unique_notes.pkl', 'wb') as f:\n",
    "    pickle.dump(df_titles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/single_key/df_titles_min_5_unique_notes.pkl', 'rb') as f:\n",
    "    df_titles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration of melodies\n",
    "durations = []\n",
    "for item in df_titles:\n",
    "    durations.append(item[0]['End'].max())\n",
    "plt.hist(durations, bins=100);\n",
    "min(durations), max(durations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitch range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_note_df = pd.read_csv('./data/midi_to_notes.csv', index_col=0)\n",
    "# dfs = [add_octave_and_note(df, midi_note_df) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range([item[0] for item in df_titles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles2 = trim_by_range(df_titles, min_range=5, max_range=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range([item[0] for item in df_titles2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/single_key/df_titles_30_min_notes_pitch_range_5_24.pkl', 'wb') as f:\n",
    "    pickle.dump(df_titles2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in dfs2:\n",
    "#     center = (df['Pitch'].max() + df['Pitch'].min()) / 2\n",
    "#     if center < 45:\n",
    "#         display(df)\n",
    "#         temp_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 5))\n",
    "# plt.plot([0], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs3 = move_octaves(dfs2, min_pitch=48, max_pitch=100)\n",
    "# dfs3 = move_octaves(dfs3, min_pitch=48, max_pitch=80)\n",
    "dfs3 = move_octaves(dfs2, center_range=[60, 72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range(dfs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/{key}/df_titles_pitch_range_min_pitch_48_max_pitch_84.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octave translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 400\n",
    "dfs3[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 44100\n",
    "midi_data = df_to_midi(dfs[sample_idx])\n",
    "audio_data = midi_data.synthesize(fs=Fs)\n",
    "ipd.Audio(audio_data, rate=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_octave_down = dfs[sample_idx].copy()\n",
    "df_octave_down['Pitch'] = df_octave_down['Pitch'] - 12\n",
    "midi_data = df_to_midi(df_octave_down)\n",
    "audio_data = midi_data.synthesize(fs=Fs)\n",
    "ipd.Audio(audio_data, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure gap between start of next note and end of previous note\n",
    "neg_gaps = []\n",
    "pos_gaps = []\n",
    "for df in dfs:\n",
    "    gap = df['Start'].iloc[1:].values - df['End'].iloc[:-1].values\n",
    "    if gap.min() < 0:\n",
    "        neg_gaps.append(df)\n",
    "    if gap.max() > 0:\n",
    "        pos_gaps.append(df)\n",
    "print(len(neg_gaps), len(pos_gaps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration + Pitch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs4 = note_duration_transform(dfs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs5, max_pitch = pitch_translation(dfs4)\n",
    "max_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_range(dfs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/{key}/dfs_note_dur_offset_{int(max_pitch)}.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/{key}/dfs_note_dur_offset_{int(max_pitch)}.pkl', 'rb') as f:\n",
    "    dfs5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NoteDurationDataset(dfs5, sample_len=20, scale=1., stride=10)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of notes within Major scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_note = {0: 'C', 1: 'C#', 2: 'D', 3: 'D#', 4: 'E', 5: 'F', 6: 'F#', 7: 'G', 8: 'G#', 9: 'A', 10: 'A#', 11: 'B'}\n",
    "key_notes = []\n",
    "for i in range(12):\n",
    "    key_notes.append(get_notes_from_major_scale(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 0\n",
    "path = f'./data/single_key/{key}/'\n",
    "# path = './data/oldies/'\n",
    "dfs = get_dfs_from_midi(path, min_notes=30, min_gap=0.)\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check percentage of notes in C major scale\n",
    "key_percentages = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 11: []}\n",
    "for df in dfs:\n",
    "    for i in range(len(key_notes)):\n",
    "        percentage = len([note for note in df['Pitch'].values if note in key_notes[i]]) / len(df['Pitch'].values)\n",
    "        key_percentages[i].append(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 3, figsize=(15, 5))\n",
    "print(f'Key: {key_to_note[key]}')\n",
    "for i in range(len(key_notes)):\n",
    "    print(f'Mean percentage of notes in key {key_to_note[i]}: {np.mean(key_percentages[i])}')\n",
    "    ax[i//3, i%3].hist(key_percentages[i], bins=100)\n",
    "    ax[i//3, i%3].set_title(f'{key_to_note[i]} major scale')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
