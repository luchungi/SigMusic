{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import IPython.display as ipd\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "%load_ext Cython\n",
    "import sigkernel as ksig\n",
    "from utils.data import *\n",
    "from model.generators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_len = 10\n",
    "sample_len = 30\n",
    "noise_dim =2\n",
    "seq_dim = 3\n",
    "scale = 1.\n",
    "stride = 800\n",
    "dpitch_range = 24\n",
    "key = 'single_key'\n",
    "\n",
    "sigma = 1.0\n",
    "kernel_type = 'truncated'\n",
    "dyadic_order = 3\n",
    "n_levels = 5\n",
    "order = 1\n",
    "\n",
    "batch_size = 64\n",
    "activation = 'Tanh'\n",
    "hidden_size = 256\n",
    "conv_kernel_size = 4\n",
    "conv_stride = 1\n",
    "n_transformer_layers = 1\n",
    "n_head = 4\n",
    "n_channels = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/dataframes/{key}/df_titles_cluster_30_min_notes_pitch_range_5_24.pkl', 'rb') as f:\n",
    "    df_titles_clusters = pickle.load(f)\n",
    "len(df_titles_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = [item[-1] for item in df_titles_clusters]\n",
    "unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "unique_labels.shape, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = []\n",
    "for i in range(unique_labels.shape[0]):\n",
    "    df_clusters.append([item for item in df_titles_clusters if item[-1] == i])\n",
    "    print(i, len(df_clusters[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(item[0]) for item in df_titles_clusters]\n",
    "print('Max length:', max(lens))\n",
    "stride = max(lens) + 1 # ensures no sampling from middle of song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gap_dur_dpitch_dfs = gap_duration_deltapitch_transform([item[0] for item in df_titles_clusters])\n",
    "# clusters = [item[4] for item in df_titles_clusters]\n",
    "# dataset = GapDurationDeltaPitchDataset(gap_dur_dpitch_dfs, sample_len=sample_len, scale=scale, stride=stride, clusters=clusters)\n",
    "\n",
    "gap_dur_dpitch_dfs = gap_duration_deltapitch_transform([item[0] for item in df_clusters[1]])\n",
    "dataset = GapDurationDeltaPitchDataset(gap_dur_dpitch_dfs, sample_len=sample_len, scale=scale, stride=stride)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "len(dataset), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_type == 'truncated':\n",
    "    static_kernel = ksig.static.kernels.RationalQuadraticKernel(sigma=sigma)\n",
    "    kernel = ksig.kernels.SignatureKernel(n_levels=n_levels, order=order, normalization=0, static_kernel=static_kernel, device_ids=None)\n",
    "elif kernel_type == 'pde':\n",
    "    static_kernel = ksig.sigkernelpde.RationalQuadraticKernel(sigma=sigma, alpha=1.0)\n",
    "    kernel = ksig.sigkernelpde.SigKernelPDE(static_kernel, dyadic_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TransInc(noise_dim, seq_dim, sample_len, hist_len, dpitch_range, # data related\n",
    "                             kernel_size=conv_kernel_size, stride=conv_stride, n_channels=n_channels, # conv layers\n",
    "                             n_head=n_head, n_transformer_layers=n_transformer_layers, # transformer layers\n",
    "                             hidden_size=hidden_size, activation=activation)\n",
    "generator = generator.cuda()\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    for batch_num, items in enumerate(tqdm(dataloader)):\n",
    "        # X, title, cluster = items\n",
    "        # cluster = cluster.to(device).unsqueeze(-1)\n",
    "        X, title = items\n",
    "\n",
    "        X = X.to(device)\n",
    "        X_rect = batch_rectilinear_with_gap_transform(X[:, hist_len:, :])\n",
    "\n",
    "        noise = torch.randn(X.shape[0], X.shape[1]-1, noise_dim).to(device)\n",
    "        Y = generator(X, noise)\n",
    "\n",
    "        Y_rect = batch_rectilinear_with_gap_transform(Y[:, hist_len:, :])\n",
    "        # print(output.shape, X.shape, X[:, :hist_len, :].shape)\n",
    "\n",
    "        # compute loss\n",
    "        optimizer.zero_grad()\n",
    "        loss = ksig.tests.mmd_loss_no_compile(X_rect, Y_rect, kernel)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backpropagate and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # log epoch loss and plot generated samples\n",
    "    epoch_loss = np.average(losses) # average batch mmd for epoch\n",
    "    scheduler.step(epoch_loss)\n",
    "    print(f'Epoch {epoch+1}, loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.load_state_dict(torch.load(f'./data/weights/gapdurdpitch_{noise_dim}z_{sample_len}l_{hist_len}h_{key}_{n_levels}m_{order}o_{hidden_size}u_{n_layers}lstm.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for items in dataloader:\n",
    "#     X, title, cluster = items\n",
    "#     X = X.to(device)\n",
    "#     cluster = cluster.to(device).unsqueeze(-1)\n",
    "#     X_rect = batch_rectilinear_with_gap_transform(X[:, hist_len:, :])\n",
    "\n",
    "#     noise = torch.randn(X.shape[0], X.shape[1]-1, noise_dim).to(device)\n",
    "#     Y = generator(noise, cluster, X[:, :hist_len, :], X[:, hist_len:, :2])\n",
    "\n",
    "#     Y_rect = batch_rectilinear_with_gap_transform(Y[:, hist_len:, :])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample and play MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titles = []\n",
    "for arg in title:\n",
    "    X_titles.append((df_titles_clusters[arg.item()][1], df_titles_clusters[arg.item()][2], df_titles_clusters[arg.item()][3]))\n",
    "start_pitch = 60\n",
    "X_dfs = batch_gap_duration_pitch_to_df(X, start_pitch=start_pitch)\n",
    "Y_dfs = batch_gap_duration_pitch_to_df(Y, start_pitch=start_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "print(X_titles[sample_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_midi = df_to_midi(X_dfs[sample_idx])\n",
    "output_midi = df_to_midi(Y_dfs[sample_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(X_dfs[sample_idx][['Start', 'End', 'Pitch']], Y_dfs[sample_idx][['Pitch']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=44100\n",
    "audio_data = input_midi.fluidsynth(fs=fs, sf2_path='./data/soundfonts/Steinway_Grand_Piano_1.2.sf2')\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=44100\n",
    "audio_data = output_midi.fluidsynth(fs=fs, sf2_path='./data/soundfonts/Steinway_Grand_Piano_1.2.sf2')\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate note within key percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_note = {0: 'C', 1: 'C#', 2: 'D', 3: 'D#', 4: 'E', 5: 'F', 6: 'F#', 7: 'G', 8: 'G#', 9: 'A', 10: 'A#', 11: 'B'}\n",
    "key_notes = []\n",
    "for i in range(12):\n",
    "    key_notes.append(get_notes_from_major_scale(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check percentage of notes in C major scale\n",
    "X_key_percentages = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 11: []}\n",
    "Y_key_percentages = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 11: []}\n",
    "for df in X_dfs:\n",
    "    for i in range(len(key_notes)):\n",
    "        percentage = len([note for note in df['Pitch'].values if note in key_notes[i]]) / len(df['Pitch'].values)\n",
    "        X_key_percentages[i].append(percentage)\n",
    "for df in Y_dfs:\n",
    "    for i in range(len(key_notes)):\n",
    "        percentage = len([note for note in df['Pitch'].values if note in key_notes[i]]) / len(df['Pitch'].values)\n",
    "        Y_key_percentages[i].append(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 3, figsize=(15, 5))\n",
    "print(f'Key: {key_to_note[start_pitch % 12]}')\n",
    "for i in range(len(key_notes)):\n",
    "    print(f'Mean percentage of notes in key {key_to_note[i]}: {np.mean(X_key_percentages[i])}')\n",
    "    ax[i//3, i%3].hist(X_key_percentages[i], bins=100)\n",
    "    ax[i//3, i%3].set_title(f'{key_to_note[i]} major scale')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 3, figsize=(15, 5))\n",
    "print(f'Key: {key_to_note[start_pitch % 12]}')\n",
    "for i in range(len(key_notes)):\n",
    "    print(f'Mean percentage of notes in key {key_to_note[i]}: {np.mean(Y_key_percentages[i])}')\n",
    "    ax[i//3, i%3].hist(Y_key_percentages[i], bins=100)\n",
    "    ax[i//3, i%3].set_title(f'{key_to_note[i]} major scale')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
