{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import IPython.display as ipd\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "%load_ext Cython\n",
    "import sigkernel as ksig\n",
    "from utils.data import *\n",
    "from model.generators import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_len = 16\n",
    "sample_len = 32 #NOTE it includes the hist_len\n",
    "noise_dim = 1\n",
    "seq_dim = 3 # (gap, duration, pitch)\n",
    "scale = 1.\n",
    "dpitch_range = 12\n",
    "stride = 800\n",
    "folder = 'theorytab'\n",
    "\n",
    "sigma = 1.0\n",
    "kernel_type = 'truncated'\n",
    "dyadic_order = 3\n",
    "n_levels = 5\n",
    "order = 1\n",
    "\n",
    "batch_size = 16\n",
    "activation = 'Tanh'\n",
    "hidden_size = 64\n",
    "n_layers = 1\n",
    "\n",
    "epochs = 50\n",
    "patience = 5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./data/dataframes/{folder}/melodies_beats_min_5_unique_max_range_24.pkl', 'rb') as f:\n",
    "with open(f'./data/dataframes/{folder}/melodies_beats_min_5_unique_max_range_24_spec_cluster_12.pkl', 'rb') as f:\n",
    "# with open(f'./data/dataframes/{folder}/all_melodies_within_key_beats_aligned_min_5_unique_max_range_21.pkl', 'rb') as f:\n",
    "    songs = pickle.load(f)\n",
    "len(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = [item[-1] for item in songs]\n",
    "unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "unique_labels.shape, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the dataframes by cluster\n",
    "df_clusters = []\n",
    "for i in range(unique_labels.shape[0]):\n",
    "    df_clusters.append([item for item in songs if item[-1] == i])\n",
    "    print(i, len(df_clusters[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(item[0]) for item in songs]\n",
    "print('Max length:', max(lens))\n",
    "stride = max(lens) + 1 # ensures no sampling from middle of song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gap_dur_dpitch_dfs = gap_duration_deltapitch_transform([item[0] for item in songs])\n",
    "# clusters = [item[4] for item in songs]\n",
    "# dataset = GapDurationDeltaPitchDataset(gap_dur_dpitch_dfs, sample_len=sample_len, scale=scale, stride=stride, clusters=clusters)\n",
    "\n",
    "# cluster_idx = 0\n",
    "# gap_dur_dpitch_dfs = gap_duration_deltapitch_transform([item[0] for item in df_clusters[cluster_idx]])\n",
    "\n",
    "gap_dur_dpitch_dfs = gap_duration_deltapitch_transform([item[0] for item in songs])\n",
    "\n",
    "dataset = GapDurationDeltaPitchDataset(gap_dur_dpitch_dfs, sample_len=sample_len, scale=scale, stride=stride)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "len(dataset), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_type == 'truncated':\n",
    "    static_kernel = ksig.static.kernels.RationalQuadraticKernel(sigma=sigma)\n",
    "    # static_kernel = ksig.static.kernels.LinearKernel()\n",
    "    kernel = ksig.kernels.SignatureKernel(n_levels=n_levels, order=order, normalization=0, static_kernel=static_kernel, device_ids=None)\n",
    "elif kernel_type == 'pde':\n",
    "    static_kernel = ksig.sigkernelpde.RationalQuadraticKernel(sigma=sigma, alpha=1.0)\n",
    "    kernel = ksig.sigkernelpde.SigKernelPDE(static_kernel, dyadic_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = LSTMgate(noise_dim, seq_dim, sample_len, hidden_size, n_layers, activation)\n",
    "# generator = LSTMinc(noise_dim, seq_dim, sample_len, dpitch_range, scale, hidden_size, n_layers, activation)\n",
    "generator = LSTMinc_v2(noise_dim, seq_dim, sample_len, dpitch_range, scale, hidden_size, n_layers, activation)\n",
    "generator = generator.cuda()\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for batch_num, items in enumerate(tqdm(dataloader)):\n",
    "        # X, title, cluster = items\n",
    "        # cluster = cluster.to(device).unsqueeze(-1)\n",
    "        X, title = items\n",
    "\n",
    "        X = X.to(device)\n",
    "        X_rect = batch_rectilinear_with_gap_transform(X[:, hist_len:, :])\n",
    "\n",
    "        # For LSTMgate\n",
    "        # noise = torch.randn(X.shape[0], X.shape[1]-1, noise_dim).to(device)\n",
    "        # Y = generator(noise, cluster, X[:, :hist_len, :], X[:, hist_len:, :2])\n",
    "\n",
    "        # For LSTMinc\n",
    "        noise = torch.randn(X.shape[0], X.shape[1]-1, noise_dim).to(device)\n",
    "        Y = generator(noise, X[:, :hist_len, :], X[:, hist_len:, :2])\n",
    "\n",
    "        Y_rect = batch_rectilinear_with_gap_transform(Y[:, hist_len:, :])\n",
    "        # print(output.shape, X.shape, X[:, :hist_len, :].shape)\n",
    "\n",
    "        # compute loss\n",
    "        optimizer.zero_grad()\n",
    "        loss = ksig.tests.mmd_loss_no_compile(X_rect, Y_rect, kernel)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backpropagate and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # log epoch loss and plot generated samples\n",
    "    epoch_loss = np.average(losses) # average batch mmd for epoch\n",
    "    scheduler.step(epoch_loss)\n",
    "    print(f'Epoch {epoch+1}, loss: {epoch_loss}')\n",
    "    # if epoch_loss < 0.:\n",
    "    #     sigma = sigma * 0.7\n",
    "    #     static_kernel = ksig.static.kernels.RationalQuadraticKernel(sigma=sigma)\n",
    "    #     kernel = ksig.kernels.SignatureKernel(n_levels=n_levels, order=order, normalization=0, static_kernel=static_kernel, device_ids=None)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, verbose=True)\n",
    "    #     print(f'New sigma: {sigma}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(generator.state_dict(), f'./data/weights/gapdurdpitch_{noise_dim}z_{sample_len}l_{hist_len}h_{key}_{n_levels}m_{order}o_{hidden_size}u_{n_layers}lstm.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.load_state_dict(torch.load(f'./data/weights/gapdurdpitch_{noise_dim}z_{sample_len}l_{hist_len}h_{key}_{n_levels}m_{order}o_{hidden_size}u_{n_layers}lstm.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample and play MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titles = []\n",
    "for arg in title:\n",
    "    X_titles.append((songs[arg.item()][1], songs[arg.item()][2], songs[arg.item()][3]))\n",
    "start_pitch = 60\n",
    "X[:,:,-1] /= scale\n",
    "Y[:,:,-1] /= scale\n",
    "X_dfs = batch_gap_duration_pitch_to_df(X, start_pitch=start_pitch)\n",
    "Y_dfs = batch_gap_duration_pitch_to_df(Y, start_pitch=start_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X_rect = batch_rectilinear_with_gap_transform(X).cpu().numpy()\n",
    "np_Y_rect = batch_rectilinear_with_gap_transform(Y).detach().cpu().numpy()\n",
    "fig, ax = plt.subplots(batch_size//4, 4, figsize=(16, batch_size//2))\n",
    "for i in range(batch_size//4):\n",
    "    for j in range(4):\n",
    "        if batch_size//4 == 1:\n",
    "            ax[j].plot(np_X_rect[j,:,0], np_X_rect[j,:,1]/scale)\n",
    "            ax[j].plot(np_Y_rect[j,:,0], np_Y_rect[j,:,1]/scale)\n",
    "            ax[j].set_title((f'{j} {X_titles[j][0]} {X_titles[j][1]}')[:50])\n",
    "        else:\n",
    "            ax[i, j].plot(np_X_rect[i*4+j,:,0], np_X_rect[i*4+j,:,1]/scale)\n",
    "            ax[i, j].plot(np_Y_rect[i*4+j,:,0], np_Y_rect[i*4+j,:,1]/scale)\n",
    "            ax[i, j].set_title((f'{i*4+j} {X_titles[i*4+j][0]} {X_titles[i*4+j][1]}')[:50])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "print(X_titles[sample_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_midi = df_to_midi(X_dfs[sample_idx])\n",
    "output_midi = df_to_midi(Y_dfs[sample_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(X_dfs[sample_idx][['Start', 'End', 'Pitch']], Y_dfs[sample_idx][['Pitch']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=44100\n",
    "audio_data = input_midi.fluidsynth(fs=fs, sf2_path='./data/soundfonts/Steinway_Grand_Piano_1.2.sf2')\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=44100\n",
    "audio_data = output_midi.fluidsynth(fs=fs, sf2_path='./data/soundfonts/Steinway_Grand_Piano_1.2.sf2')\n",
    "ipd.Audio(audio_data, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate note within key percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "Ys = []\n",
    "for item in dataloader:\n",
    "    X, title = item\n",
    "    Xs.append(X)\n",
    "    X = X.to(device)\n",
    "    X_rect = batch_rectilinear_with_gap_transform(X[:, hist_len:, :])\n",
    "\n",
    "    noise = torch.randn(X.shape[0], X.shape[1]-1, noise_dim).to(device)\n",
    "    Y = generator(noise, X[:, :hist_len, :], X[:, hist_len:, :2])\n",
    "    Ys.append(Y.detach().cpu())\n",
    "    Y_rect = batch_rectilinear_with_gap_transform(Y[:, hist_len:, :])\n",
    "\n",
    "Xs = torch.cat(Xs, dim=0)\n",
    "Ys = torch.cat(Ys, dim=0)\n",
    "print(Xs.shape, Ys.shape)\n",
    "all_X_dfs = batch_gap_duration_pitch_to_df(Xs, start_pitch=start_pitch)\n",
    "all_Y_dfs = batch_gap_duration_pitch_to_df(Ys, start_pitch=start_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_note = {0: 'C', 1: 'C#', 2: 'D', 3: 'D#', 4: 'E', 5: 'F', 6: 'F#', 7: 'G', 8: 'G#', 9: 'A', 10: 'A#', 11: 'B'}\n",
    "key_notes = []\n",
    "for i in range(12):\n",
    "    key_notes.append(get_notes_from_major_scale(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check percentage of notes in C major scale\n",
    "X_key_percentages = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 11: []}\n",
    "Y_key_percentages = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 11: []}\n",
    "for df in all_X_dfs:\n",
    "    for i in range(len(key_notes)):\n",
    "        percentage = len([note for note in df['Pitch'].values if note in key_notes[i]]) / len(df['Pitch'].values)\n",
    "        X_key_percentages[i].append(percentage)\n",
    "for df in all_Y_dfs:\n",
    "    for i in range(len(key_notes)):\n",
    "        percentage = len([note for note in df['Pitch'].values if note in key_notes[i]]) / len(df['Pitch'].values)\n",
    "        Y_key_percentages[i].append(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 3, figsize=(15, 5))\n",
    "print(f'Key: {key_to_note[start_pitch % 12]}')\n",
    "for i in range(len(key_notes)):\n",
    "    print(f'Mean percentage of notes in key {key_to_note[i]}: {np.mean(X_key_percentages[i])}')\n",
    "    ax[i//3, i%3].hist(X_key_percentages[i], bins=100)\n",
    "    ax[i//3, i%3].set_title(f'{key_to_note[i]} major scale')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 3, figsize=(15, 5))\n",
    "print(f'Key: {key_to_note[start_pitch % 12]}')\n",
    "for i in range(len(key_notes)):\n",
    "    print(f'Mean percentage of notes in key {key_to_note[i]}: {np.mean(Y_key_percentages[i])}')\n",
    "    ax[i//3, i%3].hist(Y_key_percentages[i], bins=100)\n",
    "    ax[i//3, i%3].set_title(f'{key_to_note[i]} major scale')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
