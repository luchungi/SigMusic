{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import IPython.display as ipd\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "%load_ext Cython\n",
    "\n",
    "import sigkernel as ksig\n",
    "from utils.midi import *\n",
    "from utils.data import *\n",
    "from model.generators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_len = 10\n",
    "sample_len = 50\n",
    "seq_dim = 4\n",
    "scale = 1.\n",
    "stride = 10\n",
    "min_notes = sample_len #NOTE: length of tensor might be longer than min_notes due to rectilinear transformation\n",
    "min_gap = 0.\n",
    "note_dur_transform = True\n",
    "\n",
    "rectilinear = True\n",
    "activation = 'GELU'\n",
    "hidden_size = 128\n",
    "n_transformer_layers = 1\n",
    "n_head = 4\n",
    "n_channels = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './data/maestro-v3.0.0_midi/2018/'\n",
    "path = './data/midi/'\n",
    "dfs = get_dfs_from_midi(path, min_notes=sample_len, min_gap=min_gap, note_dur_transform=note_dur_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pkl\n",
    "dfs = pd.read_pickle('./data/dfs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of dfs\n",
    "import pickle\n",
    "with open('./data/dfs_82.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, pitch_range = pitch_translation(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MIDIDataset(dfs, sample_len, cols=[0,1,2], scale=scale, stride=stride, rectilinear=rectilinear)\n",
    "dataloader = DataLoader(dataset, batch_size=50, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TransformerMusic(seq_dim, sample_len, hist_len, scale=scale, # data related\n",
    "                             kernel_size=5, stride=1, n_channels=n_channels, # conv layers\n",
    "                             n_head=n_head, n_transformer_layers=n_transformer_layers, # transformer layers\n",
    "                             hidden_size=hidden_size, activation=activation)\n",
    "generator = generator.cuda()\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_kernel = ksig.static.kernels.RationalQuadraticKernel(sigma=0.1)\n",
    "kernel = ksig.kernels.SignatureKernel(n_levels=5, order=5, normalization=0, static_kernel=static_kernel, device_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for epoch in range(30):\n",
    "    losses = [] # due to legacy code, losses is actually the mmd\n",
    "    for batch_num, X in enumerate(tqdm(dataloader)):\n",
    "        X = X.to(device)\n",
    "\n",
    "        output = generator(X)\n",
    "        X_wo_hist = X[:, hist_len:, :]\n",
    "\n",
    "        # compute loss\n",
    "        optimizer.zero_grad()\n",
    "        loss = ksig.tests.mmd_loss_no_compile(X_wo_hist, output, kernel)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backpropagate and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # log epoch loss and plot generated samples\n",
    "    epoch_loss = np.average(losses) # average batch mmd for epoch\n",
    "    scheduler.step(epoch_loss)\n",
    "    print(f'Epoch {epoch}, loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataloader:\n",
    "    x = x.to(device)\n",
    "    output = generator(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "x_np = x[i].cpu().detach().numpy()\n",
    "x_np[:, 2:] = np.round(x_np[:, 2:] * scale)\n",
    "output_np = output[i].cpu().detach().numpy()\n",
    "output_np[:, 2:] = np.round(output_np[:, 2:] * scale)\n",
    "df_x = pd.DataFrame(x_np, columns=['Start', 'End', 'Pitch', 'Velocity'])\n",
    "df_output = pd.DataFrame(output_np, columns=['Start', 'End', 'Pitch', 'Velocity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df_x.iloc[hist_len:]\n",
    "df_input.iloc[:,:2] = df_input.iloc[:,:2] - df_input.iloc[0,0]\n",
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.iloc[:,:2] = df_output.iloc[:,:2] - df_output.iloc[0,0]\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_midi = df_to_midi(df_input)\n",
    "output_midi = df_to_midi(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 22050\n",
    "audio_data = input_midi.synthesize(fs=Fs)\n",
    "ipd.Audio(audio_data, rate=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = output_midi.synthesize(fs=Fs)\n",
    "ipd.Audio(audio_data, rate=Fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
